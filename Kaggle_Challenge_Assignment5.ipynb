{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimKing100/DS-Unit-2-Kaggle-Challenge/blob/master/Kaggle_Challenge_Assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJVb6fS7521u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installs\n",
        "%%capture\n",
        "!pip install --upgrade category_encoders plotly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC18XNwu6uVK",
        "colab_type": "code",
        "outputId": "8b24bc63-e014-4a90-8098-36780a1204cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Imports\n",
        "import os, sys\n",
        "\n",
        "os.chdir('/content')\n",
        "!git init .\n",
        "!git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
        "!git pull origin master\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "os.chdir('module1')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Total 85 (delta 0), reused 0 (delta 0), pack-reused 85\u001b[K\n",
            "Unpacking objects: 100% (85/85), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Requirement already satisfied: category_encoders==2.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.0.0)\n",
            "Collecting eli5==0.10.1 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pandas-profiling==2.3.0 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 29.9MB/s \n",
            "\u001b[?25hCollecting pdpbox==0.2.0 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 103.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Collecting shap==0.30.0 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/98/16829410426bdd08b836c30e164c56646d6a102afb9eadd81a6bd3a8bb65/shap-0.30.0.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 60.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 51.1MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/19/d5f71752f71451ccc5ed5f6739e9da4a235f38783fdaf3629cae41b2ca7b/pytest-5.1.2-py3-none-any.whl (224kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 60.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.1)\n",
            "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.23)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c2/b3f73f4ac008bef6e75bca4992f3963b3f85942e0277237721ef1c151f0d/pylint-2.3.1-py3-none-any.whl (765kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 61.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Collecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 34.0MB/s \n",
            "\u001b[?25hCollecting astroid<3,>=2.2.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/ad/7221a62a2dbce5c3b8c57fd18e1052c7331adc19b3f27f1561aa6e620db2/astroid-2.2.5-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 72.5MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Collecting lazy-object-proxy (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 32.5MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.3.0; implementation_name == \"cpython\" (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 71.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-profiling, pdpbox, shap, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=122d43a3ea3db078fc98d06cc77f609368d937873a68ab771e0a0b3280e58e94\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.0-cp36-none-any.whl size=57690723 sha256=b185608f2a14ccaeacdaa508a1b093a58564b8d53aef8b705aec47a954cacd84\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.30.0-cp36-cp36m-linux_x86_64.whl size=356766 sha256=d12a1520949e9d88d835725b871308049acf3dab22c9b250596dce04fa8135cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/7a/5b/34feab81170fb8bf642a7536b5127e54e00bce373564435808\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=bcbc7b48138bd14d38cf58cd392afbefd1b0cacb41aaa329e995d005411abd91\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=186685e732ab2416c5191eb1a4f2ddb617bddee26e27d33ae2953c89b06296f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling pdpbox shap htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: eli5, htmlmin, pluggy, pytest, isort, lazy-object-proxy, typed-ast, astroid, mccabe, pylint, pytest-pylint, phik, confuse, pandas-profiling, pdpbox, shap\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.2.5 confuse-1.0.0 eli5-0.10.1 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 pdpbox-0.2.0 phik-0.9.8 pluggy-0.13.0 pylint-2.3.1 pytest-5.1.2 pytest-pylint-0.14.1 shap-0.30.0 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7MRA9WvoSpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Disable warning\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4O_RRn17vRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import sklearn\n",
        "sklearn.__version__\n",
        "\n",
        "# Import the models\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Import encoder and scaler and imputer\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMfVT1-Z7F-b",
        "colab_type": "code",
        "outputId": "811a165f-7dec-4092-f9ad-68e65831e8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import, load data and split data into train, validate and test\n",
        "train_features = pd.read_csv('../data/tanzania/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/tanzania/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "assert train_features.shape == (59400, 40)\n",
        "assert train_labels.shape == (59400, 2)\n",
        "assert test_features.shape == (14358, 40)\n",
        "assert sample_submission.shape == (14358, 2)\n",
        "\n",
        "# Load initial train features and labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train = train_features\n",
        "y_train = train_labels['status_group']\n",
        "\n",
        "# Split the initial train features and labels 80% into new train and new validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "  X_train, y_train, train_size = 0.80, test_size = 0.20,\n",
        "  stratify = y_train, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 40), (11880, 40), (47520,), (11880,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3pMJkj47Zfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wrangle train, validate, and test sets\n",
        "def wrangle(X):\n",
        "    \n",
        "    # Set bins value\n",
        "    bins=20\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # Clean installer\n",
        "    X['installer'] = X['installer'].str.lower()\n",
        "    X['installer'] = X['installer'].str.replace('danid', 'danida')\n",
        "    X['installer'] = X['installer'].str.replace('disti', 'district council')\n",
        "    X['installer'] = X['installer'].str.replace('commu', 'community')\n",
        "    X['installer'] = X['installer'].str.replace('central government', 'government')\n",
        "    X['installer'] = X['installer'].str.replace('kkkt _ konde and dwe', 'kkkt')\n",
        "    X['installer'] = X['installer'].str.lower()\n",
        "    X['installer'] = X['installer'].str[:3]\n",
        "    X['installer'].value_counts(normalize=True)\n",
        "    tops = X['installer'].value_counts()[:bins].index\n",
        "    X.loc[~X['installer'].isin(tops), 'installer'] = 'Other'\n",
        "    \n",
        "    # Clean funder and bin\n",
        "    X['funder'] = X['funder'].str.lower()\n",
        "    X['funder'] = X['funder'].str[:3]\n",
        "    X['funder'].value_counts(normalize=True)\n",
        "    tops = X['funder'].value_counts()[:bins].index\n",
        "    X.loc[~X['funder'].isin(tops), 'funder'] = 'Other'\n",
        "\n",
        "    # Use mean for gps_height missing values\n",
        "    #X.loc[X['gps_height'] == 0, 'gps_height'] = X['gps_height'].mean()\n",
        "    \n",
        "    # Bin lga\n",
        "    tops = X['lga'].value_counts()[:bins].index\n",
        "    X.loc[~X['lga'].isin(tops), 'lga'] = 'Other'\n",
        "\n",
        "    # Bin ward \n",
        "    tops = X['ward'].value_counts()[:bins].index\n",
        "    X.loc[~X['ward'].isin(tops), 'ward'] = 'Other'\n",
        "    \n",
        "    # Bin subvillage\n",
        "    tops = X_train['subvillage'].value_counts()[:bins].index\n",
        "    X_train.loc[~X_train['subvillage'].isin(tops), 'subvillage'] = 'Other'\n",
        "\n",
        "    # Clean latitude and longitude\n",
        "    average_lat = X.groupby('region').latitude.mean().reset_index()\n",
        "    average_long = X.groupby('region').longitude.mean().reset_index()\n",
        "\n",
        "    shinyanga_lat = average_lat.loc[average_lat['region'] == 'Shinyanga', 'latitude']\n",
        "    shinyanga_long = average_long.loc[average_lat['region'] == 'Shinyanga', 'longitude']\n",
        "\n",
        "    X.loc[(X['region'] == 'Shinyanga') & (X['latitude'] > -1), ['latitude']] = shinyanga_lat[17]\n",
        "    X.loc[(X['region'] == 'Shinyanga') & (X['longitude'] == 0), ['longitude']] = shinyanga_long[17]\n",
        "\n",
        "    mwanza_lat = average_lat.loc[average_lat['region'] == 'Mwanza', 'latitude']\n",
        "    mwanza_long = average_long.loc[average_lat['region'] == 'Mwanza', 'longitude']\n",
        "\n",
        "    X.loc[(X['region'] == 'Mwanza') & (X['latitude'] > -1), ['latitude']] = mwanza_lat[13]\n",
        "    X.loc[(X['region'] == 'Mwanza') & (X['longitude'] == 0) , ['longitude']] = mwanza_long[13]\n",
        "    \n",
        "    # Impute mean for tsh based on mean of source_class/basin/waterpoint_type_group\n",
        "    def tsh_calc(tsh, source, base, waterpoint):\n",
        "      if tsh == 0:\n",
        "        if (source, base, waterpoint) in tsh_dict:\n",
        "          new_tsh = tsh_dict[source, base, waterpoint]\n",
        "          return new_tsh\n",
        "      else:\n",
        "        return tsh\n",
        "      return tsh\n",
        "  \n",
        "    temp = X[X['amount_tsh'] != 0].groupby(['source_class',\n",
        "                                            'basin',\n",
        "                                            'waterpoint_type_group'])['amount_tsh'].mean()\n",
        "\n",
        "    tsh_dict = dict(temp)\n",
        "    X['amount_tsh'] = X.apply(lambda x: tsh_calc(x['amount_tsh'], x['source_class'], x['basin'], x['waterpoint_type_group']), axis=1)\n",
        "\n",
        "    # Impute mean for the feature based on latitude and longitude\n",
        "    def latlong_conversion(feature, pop, long, lat):\n",
        "    \n",
        "      radius = 0.1\n",
        "      radius_increment = 0.3\n",
        "    \n",
        "      if pop <= 1:\n",
        "        pop_temp = pop\n",
        "        while pop_temp <= 1 and radius <= 2:\n",
        "          lat_from = lat - radius\n",
        "          lat_to = lat + radius\n",
        "          long_from = long - radius\n",
        "          long_to = long + radius\n",
        "        \n",
        "          df = X[(X['latitude'] >= lat_from) & \n",
        "                 (X['latitude'] <= lat_to) &\n",
        "                 (X['longitude'] >= long_from) &\n",
        "                 (X['longitude'] <= long_to)]\n",
        "        \n",
        "          pop_temp = df[feature].mean()\n",
        "          if math.isnan(pop_temp):\n",
        "            pop_temp = pop\n",
        "          radius = radius + radius_increment\n",
        "      else:\n",
        "        pop_temp = pop\n",
        "      \n",
        "      if pop_temp <= 1:\n",
        "        new_pop = X_train[feature].mean()\n",
        "      else:\n",
        "        new_pop = pop_temp\n",
        "        \n",
        "      return new_pop\n",
        "    \n",
        "    # Impute gps_height based on location\n",
        "    #X['population'] = X.apply(lambda x: latlong_conversion('population', x['gps_height'], x['longitude'], x['latitude']), axis=1)\n",
        "    \n",
        "    # Impute gps_height based on location\n",
        "    X['gps_height'] = X.apply(lambda x: latlong_conversion('gps_height', x['gps_height'], x['longitude'], x['latitude']), axis=1)\n",
        "                  \n",
        "    # quantity & quantity_group are duplicates, so drop quantity_group\n",
        "    X = X.drop(columns='quantity_group')\n",
        "    X = X.drop(columns='num_private')\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BseDmCdj5Cx4",
        "colab_type": "code",
        "outputId": "a678a0a5-ecb7-4acd-eb5a-517061c421f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "# Wrangle the data\n",
        "X_train = wrangle(X_train)\n",
        "X_val = wrangle(X_val)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRfrHKHsFnaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature engineering\n",
        "def feature_engineer(X):\n",
        "  \n",
        "  # Create new feature pump_age\n",
        "  X['pump_age'] = 2013 - X['construction_year']\n",
        "  X.loc[X['pump_age'] == 2013, 'pump_age'] = 0\n",
        "  X.loc[X['pump_age'] == 0, 'pump_age'] = 10\n",
        "  \n",
        "  # Create new feature region_district\n",
        "  X['region_district'] = X['region_code'].astype(str) + X['district_code'].astype(str)\n",
        "\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8Q3F8oGw9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature engineer the data\n",
        "X_train = feature_engineer(X_train)\n",
        "X_val = feature_engineer(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVA3GqdUC47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode a feature\n",
        "def encode_feature(X, y, str):\n",
        "  X['status_group'] = y\n",
        "  X.groupby(str)['status_group'].value_counts(normalize=True)\n",
        "  X['functional']= (X['status_group'] == 'functional').astype(int)\n",
        "  X[['status_group', 'functional']]\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEfqrCtxWhiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode all the categorical features\n",
        "train = X_train.copy()\n",
        "train = encode_feature(train, y_train, 'quantity')\n",
        "train = encode_feature(train, y_train, 'waterpoint_type')\n",
        "train = encode_feature(train, y_train, 'extraction_type')\n",
        "train = encode_feature(train, y_train, 'installer')\n",
        "train = encode_feature(train, y_train, 'basin')\n",
        "train = encode_feature(train, y_train, 'region')\n",
        "train = encode_feature(train, y_train, 'payment')\n",
        "train = encode_feature(train, y_train, 'source')\n",
        "train = encode_feature(train, y_train, 'lga')\n",
        "train = encode_feature(train, y_train, 'scheme_management')\n",
        "train = encode_feature(train, y_train, 'management')\n",
        "train = encode_feature(train, y_train, 'region_code')\n",
        "train = encode_feature(train, y_train, 'subvillage')\n",
        "train = encode_feature(train, y_train, 'funder')\n",
        "train = encode_feature(train, y_train, 'water_quality')\n",
        "train = encode_feature(train, y_train, 'ward')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Y1U6xKHiGW",
        "colab_type": "code",
        "outputId": "b8f1bf0a-9127-4601-bc26-70258c3506b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# use quantity feature and the numerical features but drop id\n",
        "categorical_features = ['quantity', 'waterpoint_type', 'extraction_type', 'installer',\n",
        "                         'basin', 'region', 'payment', 'source', 'lga', 'public_meeting',\n",
        "                         'scheme_management', 'permit', 'management', 'region_district',\n",
        "                         'subvillage', 'funder', 'water_quality', 'ward']\n",
        "                                              \n",
        "numeric_features = X_train.select_dtypes('number').columns.drop('id').tolist()\n",
        "features = categorical_features + numeric_features\n",
        "\n",
        "# make subsets using the quantity feature all numeric features except id\n",
        "X_train = X_train[features]\n",
        "X_val = X_val[features]\n",
        "\n",
        "# Create the logistic regression pipeline\n",
        "pipeline = make_pipeline (\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    StandardScaler(),\n",
        "    LogisticRegressionCV(n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))         "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7515151515151515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq_J0c5GpPx3",
        "colab_type": "code",
        "outputId": "c1f36964-6768-4f64-f8f7-d276ed63bf57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Create the random forest pipeline\n",
        "pipeline = make_pipeline (\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    StandardScaler(),\n",
        "    RandomForestClassifier(n_estimators=1000, \n",
        "                               random_state=42,\n",
        "                               max_features = 'auto',\n",
        "                               n_jobs=-1,\n",
        "                               verbose = 1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))         \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   14.0s\n",
            "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   32.1s\n",
            "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   57.5s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.2min finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8111111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZMpgC0GLX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "6722fbad-9544-43e0-d86f-2c111e58ceef"
      },
      "source": [
        "test_features['pump_age'] = 2013 - test_features['construction_year']\n",
        "test_features.loc[test_features['pump_age'] == 2013, 'pump_age'] = 0\n",
        "test_features.loc[test_features['pump_age'] == 0, 'pump_age'] = 10\n",
        "  \n",
        "test_features['region_district'] = test_features['region_code'].astype(str) + test_features['district_code'].astype(str)\n",
        "\n",
        "test_features.drop(columns=['num_private'])\n",
        "\n",
        "X_test = test_features[features]\n",
        "\n",
        "assert all(X_test.columns == X_train.columns)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.3s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PQd-OKqGPT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = sample_submission.copy()\n",
        "submission['status_group'] = y_pred\n",
        "submission.to_csv('/content/submission-01.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}