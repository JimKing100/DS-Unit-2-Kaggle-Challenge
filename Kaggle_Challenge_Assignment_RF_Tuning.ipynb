{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimKing100/DS-Unit-2-Kaggle-Challenge/blob/master/Kaggle_Challenge_Assignment_RF_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJVb6fS7521u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installs\n",
        "%%capture\n",
        "!pip install --upgrade category_encoders plotly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC18XNwu6uVK",
        "colab_type": "code",
        "outputId": "55b63042-f64d-46da-841e-a7e2f185210b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Imports\n",
        "import os, sys\n",
        "\n",
        "os.chdir('/content')\n",
        "!git init .\n",
        "!git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
        "!git pull origin master\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "os.chdir('module1')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "fatal: remote origin already exists.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Requirement already satisfied: category_encoders==2.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: eli5==0.10.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Requirement already satisfied: pandas-profiling==2.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.3.0)\n",
            "Requirement already satisfied: pdpbox==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Requirement already satisfied: shap==0.30.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.30.0)\n",
            "Requirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: phik>=0.9.8 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.9.8)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.12)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.1)\n",
            "Requirement already satisfied: pytest-pylint>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Requirement already satisfied: pytest>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: pylint>=1.4.5 in /usr/local/lib/python3.6/dist-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.3.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.13.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: astroid<3,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.2.5)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: isort<5,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.3.21)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: typed-ast>=1.3.0; implementation_name == \"cpython\" in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7MRA9WvoSpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Disable warning\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4O_RRn17vRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import sklearn\n",
        "sklearn.__version__\n",
        "\n",
        "# Import the models\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Import encoder and scaler and imputer\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMfVT1-Z7F-b",
        "colab_type": "code",
        "outputId": "b850bd9e-d1a2-463f-e305-72c12b5352e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import, load data and split data into train, validate and test\n",
        "train_features = pd.read_csv('../data/tanzania/train_features.csv')\n",
        "train_labels = pd.read_csv('../data/tanzania/train_labels.csv')\n",
        "test_features = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "assert train_features.shape == (59400, 40)\n",
        "assert train_labels.shape == (59400, 2)\n",
        "assert test_features.shape == (14358, 40)\n",
        "assert sample_submission.shape == (14358, 2)\n",
        "\n",
        "# Load initial train features and labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train = train_features\n",
        "y_train = train_labels['status_group']\n",
        "\n",
        "# Split the initial train features and labels 80% into new train and new validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "  X_train, y_train, train_size = 0.80, test_size = 0.20,\n",
        "  stratify = y_train, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 40), (11880, 40), (47520,), (11880,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3pMJkj47Zfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Wrangle train, validate, and test sets\n",
        "def wrangle(X):\n",
        "    \n",
        "    # Set bins value\n",
        "    bins=20\n",
        "    chars = 3\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # Create missing columns\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    \n",
        "    for col in cols_with_zeros:\n",
        "        print(col)\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_missing'] = X[col].isnull()\n",
        "    \n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(np.nan, 0)\n",
        "    \n",
        "    # Clean installer\n",
        "    X['installer'] = X['installer'].str.lower()\n",
        "    X['installer'] = X['installer'].str.replace('danid', 'danida')\n",
        "    X['installer'] = X['installer'].str.replace('disti', 'district council')\n",
        "    X['installer'] = X['installer'].str.replace('commu', 'community')\n",
        "    X['installer'] = X['installer'].str.replace('central government', 'government')\n",
        "    X['installer'] = X['installer'].str.replace('kkkt _ konde and dwe', 'kkkt')\n",
        "    X['installer'] = X['installer'].str[:chars]\n",
        "    X['installer'].value_counts(normalize=True)\n",
        "    tops = X['installer'].value_counts()[:bins].index\n",
        "    X.loc[~X['installer'].isin(tops), 'installer'] = 'Other'\n",
        "    \n",
        "    # Clean funder and bin\n",
        "    X['funder'] = X['funder'].str.lower()\n",
        "    X['funder'] = X['funder'].str[:chars]\n",
        "    X['funder'].value_counts(normalize=True)\n",
        "    tops = X['funder'].value_counts()[:bins].index\n",
        "    X.loc[~X['funder'].isin(tops), 'funder'] = 'Other'\n",
        "\n",
        "    # Use mean for gps_height missing values\n",
        "    #X.loc[X['gps_height'] == 0, 'gps_height'] = X['gps_height'].median()\n",
        "    \n",
        "    # Bin lga\n",
        "    tops = X['lga'].value_counts()[:bins].index\n",
        "    X.loc[~X['lga'].isin(tops), 'lga'] = 'Other'\n",
        "\n",
        "    # Bin ward \n",
        "    tops = X['ward'].value_counts()[:bins].index\n",
        "    X.loc[~X['ward'].isin(tops), 'ward'] = 'Other'\n",
        "    \n",
        "    # Bin subvillage\n",
        "    tops = X['subvillage'].value_counts()[:bins].index\n",
        "    X.loc[~X['subvillage'].isin(tops), 'subvillage'] = 'Other'\n",
        "\n",
        "    # Clean latitude and longitude\n",
        "    avg_lat_ward = X.groupby('ward').latitude.mean()\n",
        "    avg_lat_lga = X.groupby('lga').latitude.mean()\n",
        "    avg_lat_region = X.groupby('region').latitude.mean()\n",
        "    avg_lat_country = X.latitude.mean()\n",
        "    \n",
        "    avg_long_ward = X.groupby('ward').longitude.mean()\n",
        "    avg_long_lga = X.groupby('lga').longitude.mean()\n",
        "    avg_long_region = X.groupby('region').longitude.mean()\n",
        "    avg_long_country = X.longitude.mean()\n",
        "    \n",
        "    \n",
        "    #cols_with_zeros = ['longitude', 'latitude']\n",
        "    #for col in cols_with_zeros:\n",
        "    #    X[col] = X[col].replace(0, np.nan)\n",
        "    #X.loc[X['latitude'] == 0, 'latitude'] = X['latitude'].median()\n",
        "    #X.loc[X['longitude'] == 0, 'longitude'] = X['longitude'].median()\n",
        "    \n",
        "    for i in range(0, 9): \n",
        "  \n",
        "      X.loc[(X['latitude'] == 0) & (X['ward'] == avg_lat_ward.index[0]), 'latitude'] = avg_lat_ward[i]\n",
        "      X.loc[(X['latitude'] == 0) & (X['lga'] == avg_lat_lga.index[0]), 'latitude'] = avg_lat_lga[i]\n",
        "      X.loc[(X['latitude'] == 0) & (X['region'] == avg_lat_region.index[0]), 'latitude'] = avg_lat_region[i]\n",
        "      X.loc[(X['latitude'] == 0), 'latitude'] = avg_lat_country\n",
        "\n",
        "      X.loc[(X['longitude'] == 0) & (X['ward'] == avg_long_ward.index[0]), 'longitude'] = avg_long_ward[i]\n",
        "      X.loc[(X['longitude'] == 0) & (X['lga'] == avg_long_lga.index[0]), 'longitude'] = avg_long_lga[i]\n",
        "      X.loc[(X['longitude'] == 0) & (X['region'] == avg_long_region.index[0]), 'longitude'] = avg_long_region[i]\n",
        "      X.loc[(X['longitude'] == 0), 'longitude'] = avg_long_country\n",
        "   \n",
        "    #average_lat = X.groupby('region').latitude.mean().reset_index()\n",
        "    #average_long = X.groupby('region').longitude.mean().reset_index()\n",
        "\n",
        "    #shinyanga_lat = average_lat.loc[average_lat['region'] == 'Shinyanga', 'latitude']\n",
        "    #shinyanga_long = average_long.loc[average_lat['region'] == 'Shinyanga', 'longitude']\n",
        "\n",
        "    #X.loc[(X['region'] == 'Shinyanga') & (X['latitude'] > -1), ['latitude']] = shinyanga_lat[17]\n",
        "    #X.loc[(X['region'] == 'Shinyanga') & (X['longitude'] == 0), ['longitude']] = shinyanga_long[17]\n",
        "\n",
        "    #mwanza_lat = average_lat.loc[average_lat['region'] == 'Mwanza', 'latitude']\n",
        "    #mwanza_long = average_long.loc[average_lat['region'] == 'Mwanza', 'longitude']\n",
        "\n",
        "    #X.loc[(X['region'] == 'Mwanza') & (X['latitude'] > -1), ['latitude']] = mwanza_lat[13]\n",
        "    #X.loc[(X['region'] == 'Mwanza') & (X['longitude'] == 0) , ['longitude']] = mwanza_long[13]\n",
        "    \n",
        "    # Impute mean for tsh based on mean of source_class/basin/waterpoint_type_group\n",
        "    def tsh_calc(tsh, source, base, waterpoint):\n",
        "      if tsh == 0:\n",
        "        if (source, base, waterpoint) in tsh_dict:\n",
        "          new_tsh = tsh_dict[source, base, waterpoint]\n",
        "          return new_tsh\n",
        "      else:\n",
        "        return tsh\n",
        "      return tsh\n",
        "  \n",
        "    temp = X[X['amount_tsh'] != 0].groupby(['source_class',\n",
        "                                            'basin',\n",
        "                                            'waterpoint_type_group'])['amount_tsh'].mean()\n",
        "\n",
        "    tsh_dict = dict(temp)\n",
        "    X['amount_tsh'] = X.apply(lambda x: tsh_calc(x['amount_tsh'], x['source_class'], x['basin'], x['waterpoint_type_group']), axis=1)\n",
        "    #X.loc[X['amount_tsh'] == 0, 'amount_tsh'] = X['amount_tsh'].median()\n",
        "    \n",
        "    # Impute mean for construction_year based on mean of source_class/basin/waterpoint_type_group\n",
        "    temp = X[X['construction_year'] != 0].groupby(['source_class',\n",
        "                                                   'basin',\n",
        "                                                   'waterpoint_type_group'])['amount_tsh'].mean()\n",
        "\n",
        "    tsh_dict = dict(temp)\n",
        "    X['construction_year'] = X.apply(lambda x: tsh_calc(x['construction_year'], x['source_class'], x['basin'], x['waterpoint_type_group']), axis=1)\n",
        "    #X.loc[X['construction_year'] == 0, 'construction_year'] = X['construction_year'].median()\n",
        "    \n",
        "    # Impute mean for the feature based on latitude and longitude\n",
        "    def latlong_conversion(feature, pop, long, lat):\n",
        "    \n",
        "      radius = 0.1\n",
        "      radius_increment = 0.3\n",
        "    \n",
        "      if pop <= 1:\n",
        "        pop_temp = pop\n",
        "        while pop_temp <= 1 and radius <= 2:\n",
        "          lat_from = lat - radius\n",
        "          lat_to = lat + radius\n",
        "          long_from = long - radius\n",
        "          long_to = long + radius\n",
        "        \n",
        "          df = X[(X['latitude'] >= lat_from) & \n",
        "                 (X['latitude'] <= lat_to) &\n",
        "                 (X['longitude'] >= long_from) &\n",
        "                 (X['longitude'] <= long_to)]\n",
        "        \n",
        "          pop_temp = df[feature].mean()\n",
        "          if math.isnan(pop_temp):\n",
        "            pop_temp = pop\n",
        "          radius = radius + radius_increment\n",
        "      else:\n",
        "        pop_temp = pop\n",
        "      \n",
        "      if pop_temp <= 1:\n",
        "        new_pop = X_train[feature].mean()\n",
        "      else:\n",
        "        new_pop = pop_temp\n",
        "        \n",
        "      return new_pop\n",
        "    \n",
        "    # Impute population based on location\n",
        "    #X['population'] = X.apply(lambda x: latlong_conversion('population', x['population'], x['longitude'], x['latitude']), axis=1)\n",
        "    #X.loc[X['population'] == 0, 'population'] = X['population'].median()\n",
        "    \n",
        "    # Impute gps_height based on location\n",
        "    X['gps_height'] = X.apply(lambda x: latlong_conversion('gps_height', x['gps_height'], x['longitude'], x['latitude']), axis=1)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random) and num_private (empty)\n",
        "    unusable_variance = ['recorded_by', 'id', 'num_private','wpt_name', 'extraction_type_class',\n",
        "                         'quality_group', 'source_type', 'source_class', 'waterpoint_type_group']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type', 'extraction_type_group']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BseDmCdj5Cx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a15aa548-ae96-41f8-e558-d7b3c342f4bf"
      },
      "source": [
        "# Wrangle the data\n",
        "X_train = wrangle(X_train)\n",
        "X_val = wrangle(X_val)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "longitude\n",
            "latitude\n",
            "construction_year\n",
            "gps_height\n",
            "population\n",
            "longitude\n",
            "latitude\n",
            "construction_year\n",
            "gps_height\n",
            "population\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRfrHKHsFnaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature engineering\n",
        "def feature_engineer(X):\n",
        "  \n",
        "  # Create new feature pump_age\n",
        "  X['pump_age'] = 2013 - X['construction_year']\n",
        "  X.loc[X['pump_age'] == 2013, 'pump_age'] = 0\n",
        "  X.loc[X['pump_age'] == 0, 'pump_age'] = 10\n",
        "  \n",
        "  \n",
        "  # Convert date_recorded to datetime\n",
        "  X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "  # Extract components from date_recorded, then drop the original column\n",
        "  X['year_recorded'] = X['date_recorded'].dt.year\n",
        "  X['month_recorded'] = X['date_recorded'].dt.month\n",
        "  X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    \n",
        "  # Engineer feature: how many years from construction_year to date_recorded\n",
        "  X['years'] = X['year_recorded'] - X['construction_year']\n",
        "  X['years_missing'] = X['years'].isnull()\n",
        "  \n",
        "  column_list = ['date_recorded']\n",
        "  X = X.drop(columns=column_list)\n",
        "  \n",
        "  # Create new feature region_district\n",
        "  #X['region_district'] = X['region_code'].astype(str) + X['district_code'].astype(str)\n",
        "  \n",
        "  #X['tsh_pop'] = X['amount_tsh']/X['population']\n",
        "\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck8Q3F8oGw9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature engineer the data\n",
        "X_train = feature_engineer(X_train)\n",
        "X_val = feature_engineer(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdLdgb5lTrWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "886b6516-81c1-4e94-de10-db0a5b51833f"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>funder</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>installer</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>basin</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>region</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>lga</th>\n",
              "      <th>ward</th>\n",
              "      <th>population</th>\n",
              "      <th>public_meeting</th>\n",
              "      <th>scheme_management</th>\n",
              "      <th>scheme_name</th>\n",
              "      <th>permit</th>\n",
              "      <th>construction_year</th>\n",
              "      <th>extraction_type</th>\n",
              "      <th>management</th>\n",
              "      <th>management_group</th>\n",
              "      <th>payment</th>\n",
              "      <th>water_quality</th>\n",
              "      <th>quantity</th>\n",
              "      <th>source</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>longitude_missing</th>\n",
              "      <th>latitude_missing</th>\n",
              "      <th>construction_year_missing</th>\n",
              "      <th>gps_height_missing</th>\n",
              "      <th>population_missing</th>\n",
              "      <th>pump_age</th>\n",
              "      <th>year_recorded</th>\n",
              "      <th>month_recorded</th>\n",
              "      <th>day_recorded</th>\n",
              "      <th>years</th>\n",
              "      <th>years_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43360</th>\n",
              "      <td>1415.482234</td>\n",
              "      <td>Other</td>\n",
              "      <td>20.655640</td>\n",
              "      <td>Other</td>\n",
              "      <td>33.542898</td>\n",
              "      <td>-9.174777</td>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Other</td>\n",
              "      <td>Mbeya</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>Rungwe</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>VWC</td>\n",
              "      <td>K</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1415.110875</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>spring</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>597.889125</td>\n",
              "      <td>2011</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>595.889125</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>500.000000</td>\n",
              "      <td>Other</td>\n",
              "      <td>2049.000000</td>\n",
              "      <td>Other</td>\n",
              "      <td>34.665760</td>\n",
              "      <td>-9.308548</td>\n",
              "      <td>Rufiji</td>\n",
              "      <td>Other</td>\n",
              "      <td>Iringa</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>Njombe</td>\n",
              "      <td>Imalinyi</td>\n",
              "      <td>175.0</td>\n",
              "      <td>True</td>\n",
              "      <td>WUA</td>\n",
              "      <td>Tove Mtwango gravity Scheme</td>\n",
              "      <td>True</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>gravity</td>\n",
              "      <td>wua</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay monthly</td>\n",
              "      <td>soft</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>23</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>Other</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>Other</td>\n",
              "      <td>38.238568</td>\n",
              "      <td>-6.179919</td>\n",
              "      <td>Wami / Ruvu</td>\n",
              "      <td>Other</td>\n",
              "      <td>Pwani</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>Bagamoyo</td>\n",
              "      <td>Other</td>\n",
              "      <td>2300.0</td>\n",
              "      <td>True</td>\n",
              "      <td>VWC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>india mark ii</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay per bucket</td>\n",
              "      <td>salty</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>391.538462</td>\n",
              "      <td>gov</td>\n",
              "      <td>4.781262</td>\n",
              "      <td>dwe</td>\n",
              "      <td>30.716727</td>\n",
              "      <td>-1.289055</td>\n",
              "      <td>Lake Victoria</td>\n",
              "      <td>Other</td>\n",
              "      <td>Kagera</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>Karagwe</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>389.075055</td>\n",
              "      <td>other</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>soft</td>\n",
              "      <td>enough</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>other</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1623.924945</td>\n",
              "      <td>2011</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>1621.924945</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52726</th>\n",
              "      <td>1267.552189</td>\n",
              "      <td>wat</td>\n",
              "      <td>67.488372</td>\n",
              "      <td>gov</td>\n",
              "      <td>35.389331</td>\n",
              "      <td>-6.399942</td>\n",
              "      <td>Internal</td>\n",
              "      <td>Other</td>\n",
              "      <td>Dodoma</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Other</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>VWC</td>\n",
              "      <td>Zeje</td>\n",
              "      <td>True</td>\n",
              "      <td>1270.526091</td>\n",
              "      <td>mono</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay per bucket</td>\n",
              "      <td>soft</td>\n",
              "      <td>enough</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>742.473909</td>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>740.473909</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        amount_tsh funder  ...        years years_missing\n",
              "43360  1415.482234  Other  ...   595.889125         False\n",
              "7263    500.000000  Other  ...     3.000000         False\n",
              "2486     25.000000  Other  ...     1.000000         False\n",
              "313     391.538462    gov  ...  1621.924945         False\n",
              "52726  1267.552189    wat  ...   740.473909         False\n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOVA3GqdUC47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode a feature\n",
        "def encode_feature(X, y, str):\n",
        "  X['status_group'] = y\n",
        "  X.groupby(str)['status_group'].value_counts(normalize=True)\n",
        "  X['functional']= (X['status_group'] == 'functional').astype(int)\n",
        "  X[['status_group', 'functional']]\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEfqrCtxWhiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode all the categorical features\n",
        "train = X_train.copy()\n",
        "train = encode_feature(train, y_train, 'quantity')\n",
        "train = encode_feature(train, y_train, 'waterpoint_type')\n",
        "train = encode_feature(train, y_train, 'extraction_type')\n",
        "train = encode_feature(train, y_train, 'installer')\n",
        "train = encode_feature(train, y_train, 'funder')\n",
        "train = encode_feature(train, y_train, 'water_quality')\n",
        "train = encode_feature(train, y_train, 'basin')\n",
        "train = encode_feature(train, y_train, 'region')\n",
        "train = encode_feature(train, y_train, 'payment')\n",
        "train = encode_feature(train, y_train, 'source')\n",
        "train = encode_feature(train, y_train, 'lga')\n",
        "train = encode_feature(train, y_train, 'ward')\n",
        "train = encode_feature(train, y_train, 'scheme_management')\n",
        "train = encode_feature(train, y_train, 'management')\n",
        "#train = encode_feature(train, y_train, 'region_district')\n",
        "train = encode_feature(train, y_train, 'subvillage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Y1U6xKHiGW",
        "colab_type": "code",
        "outputId": "bee909a6-7256-4c1e-ce0b-9069f89dd4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# use quantity feature and the numerical features but drop id\n",
        "categorical_features = ['quantity', 'waterpoint_type', 'extraction_type', 'installer',\n",
        "                        'funder', 'water_quality', 'basin', 'region', 'payment', \n",
        "                        'source', 'lga', 'ward', 'scheme_management', 'management', 'subvillage',\n",
        "                        'permit']\n",
        "                                              \n",
        "#numeric_features = X_train.select_dtypes('number').columns.drop('id').tolist()\n",
        "numeric_features = X_train.select_dtypes('number').columns.tolist()\n",
        "features = categorical_features + numeric_features\n",
        "\n",
        "# make subsets using the quantity feature all numeric features except id\n",
        "X_train = X_train[features]\n",
        "X_val = X_val[features]\n",
        "\n",
        "# Create the logistic regression pipeline\n",
        "pipeline = make_pipeline (\n",
        "    ce.OneHotEncoder(use_cat_names=True),\n",
        "    #SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegressionCV(random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))         "
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7407407407407407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4IK8zxUBP3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "3e1bedbc-e41d-41b1-e7f8-de9e5fd8f99f"
      },
      "source": [
        "features"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['quantity',\n",
              " 'waterpoint_type',\n",
              " 'extraction_type',\n",
              " 'installer',\n",
              " 'funder',\n",
              " 'water_quality',\n",
              " 'basin',\n",
              " 'region',\n",
              " 'payment',\n",
              " 'source',\n",
              " 'lga',\n",
              " 'ward',\n",
              " 'scheme_management',\n",
              " 'management',\n",
              " 'subvillage',\n",
              " 'permit',\n",
              " 'amount_tsh',\n",
              " 'gps_height',\n",
              " 'longitude',\n",
              " 'latitude',\n",
              " 'region_code',\n",
              " 'district_code',\n",
              " 'population',\n",
              " 'construction_year',\n",
              " 'pump_age',\n",
              " 'year_recorded',\n",
              " 'month_recorded',\n",
              " 'day_recorded',\n",
              " 'years']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq_J0c5GpPx3",
        "colab_type": "code",
        "outputId": "775fb4ff-5e6d-4834-866f-d9a52b9ff806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Create the random forest pipeline\n",
        "categorical_features = ['quantity', 'waterpoint_type', 'extraction_type', 'installer',\n",
        "                        'funder', 'water_quality', 'basin', 'region', 'payment', \n",
        "                        'source', 'lga', 'ward', 'scheme_management', 'management', 'subvillage',\n",
        "                        'permit']\n",
        "                                              \n",
        "#numeric_features = X_train.select_dtypes('number').columns.drop('id').tolist()\n",
        "#numeric_features = X_train.select_dtypes('number').columns.tolist()\n",
        "numeric_features = ['amount_tsh','gps_height', 'latitude', 'longitude','region_code','district_code',\n",
        "                    'population', 'construction_year','pump_age','year_recorded','month_recorded',\n",
        "                    'day_recorded', 'years']\n",
        "ordinal_features = []\n",
        "features = categorical_features + numeric_features\n",
        "\n",
        "\n",
        "pipeline = make_pipeline (\n",
        "    #ce.OrdinalEncoder(features),\n",
        "    ce.OneHotEncoder(features),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    RandomForestClassifier(n_estimators=1000, \n",
        "                           random_state=42,\n",
        "                           max_features = 'auto',\n",
        "                           n_jobs=-1,\n",
        "                           verbose = 1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))         "
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   20.6s\n",
            "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   36.8s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   46.6s finished\n",
            "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8132996632996633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    1.5s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUAdncye8hFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "9d4b9d4f-0032-4008-8fdc-d8a19afa4a1a"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-9JiJj3A1dS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e9e14193-0959-427b-fc88-f141a4c6a88f"
      },
      "source": [
        "y_train.unique()\n",
        "\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['functional', 'non functional', 'functional needs repair'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Koy1QAHsIMPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.where(y_train == 'functional', 1, y_train)\n",
        "y_train = np.where(y_train == 'non functional', 2, y_train)\n",
        "y_train = np.where(y_train == 'functional needs repair', 2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6sQahwFJUGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ade50457-5ed1-460a-d323-08e617736362"
      },
      "source": [
        "y_train\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 2, 1, 1], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sIv0MXLB2uj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1919b477-8aa3-4721-b9f8-64a9c2c65ad7"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Create the random forest pipeline\n",
        "categorical_features = ['quantity', 'waterpoint_type', 'extraction_type', 'installer',\n",
        "                        'funder', 'water_quality', 'basin', 'region', 'payment', \n",
        "                        'source', 'lga', 'ward', 'scheme_management', 'management', 'subvillage',\n",
        "                        'permit']\n",
        "                                              \n",
        "#numeric_features = X_train.select_dtypes('number').columns.drop('id').tolist()\n",
        "#numeric_features = X_train.select_dtypes('number').columns.tolist()\n",
        "numeric_features = ['amount_tsh','gps_height', 'latitude', 'longitude','region_code','district_code',\n",
        "                    'population', 'construction_year','pump_age','year_recorded','month_recorded',\n",
        "                    'day_recorded', 'years']\n",
        "ordinal_features = []\n",
        "features = categorical_features + numeric_features\n",
        "\n",
        "pipeline = make_pipeline (\n",
        "    #ce.OrdinalEncoder(features),\n",
        "    ce.OneHotEncoder(features),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    RandomizedSearchCV(estimator = RandomForestRegressor(),\n",
        "                       param_distributions = random_grid,\n",
        "                       n_iter = 10,\n",
        "                       verbose=2,\n",
        "                       random_state=42,\n",
        "                       n_jobs = -1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 123.3min finished\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 123.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('onehotencoder',\n",
              "                 OneHotEncoder(cols=['quantity', 'waterpoint_type',\n",
              "                                     'extraction_type', 'installer', 'funder',\n",
              "                                     'water_quality', 'basin', 'region',\n",
              "                                     'payment', 'source', 'lga', 'ward',\n",
              "                                     'scheme_management', 'management',\n",
              "                                     'subvillage', 'permit'],\n",
              "                               drop_invariant=False, handle_missing='value',\n",
              "                               handle_unknown='value', return_df=True,\n",
              "                               use_cat_names=...\n",
              "                                    param_distributions={'bootstrap': [True,\n",
              "                                                                       False],\n",
              "                                                         'max_depth': [10, 20,\n",
              "                                                                       30, 40,\n",
              "                                                                       50, 60,\n",
              "                                                                       70, 80,\n",
              "                                                                       90, 100,\n",
              "                                                                       110,\n",
              "                                                                       None],\n",
              "                                                         'max_features': ['auto',\n",
              "                                                                          'sqrt'],\n",
              "                                                         'min_samples_leaf': [1,\n",
              "                                                                              2,\n",
              "                                                                              4],\n",
              "                                                         'min_samples_split': [2,\n",
              "                                                                               5,\n",
              "                                                                               10],\n",
              "                                                         'n_estimators': [200,\n",
              "                                                                          400,\n",
              "                                                                          600,\n",
              "                                                                          800,\n",
              "                                                                          1000,\n",
              "                                                                          1200,\n",
              "                                                                          1400,\n",
              "                                                                          1600,\n",
              "                                                                          1800,\n",
              "                                                                          2000]},\n",
              "                                    pre_dispatch='2*n_jobs', random_state=42,\n",
              "                                    refit=True, return_train_score=False,\n",
              "                                    scoring=None, verbose=2))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('onehotencoder',\n",
              "                 OneHotEncoder(cols=['quantity', 'waterpoint_type',\n",
              "                                     'extraction_type', 'installer', 'funder',\n",
              "                                     'water_quality', 'basin', 'region',\n",
              "                                     'payment', 'source', 'lga', 'ward',\n",
              "                                     'scheme_management', 'management',\n",
              "                                     'subvillage', 'permit'],\n",
              "                               drop_invariant=False, handle_missing='value',\n",
              "                               handle_unknown='value', return_df=True,\n",
              "                               use_cat_names=...\n",
              "                                    param_distributions={'bootstrap': [True,\n",
              "                                                                       False],\n",
              "                                                         'max_depth': [10, 20,\n",
              "                                                                       30, 40,\n",
              "                                                                       50, 60,\n",
              "                                                                       70, 80,\n",
              "                                                                       90, 100,\n",
              "                                                                       110,\n",
              "                                                                       None],\n",
              "                                                         'max_features': ['auto',\n",
              "                                                                          'sqrt'],\n",
              "                                                         'min_samples_leaf': [1,\n",
              "                                                                              2,\n",
              "                                                                              4],\n",
              "                                                         'min_samples_split': [2,\n",
              "                                                                               5,\n",
              "                                                                               10],\n",
              "                                                         'n_estimators': [200,\n",
              "                                                                          400,\n",
              "                                                                          600,\n",
              "                                                                          800,\n",
              "                                                                          1000,\n",
              "                                                                          1200,\n",
              "                                                                          1400,\n",
              "                                                                          1600,\n",
              "                                                                          1800,\n",
              "                                                                          2000]},\n",
              "                                    pre_dispatch='2*n_jobs', random_state=42,\n",
              "                                    refit=True, return_train_score=False,\n",
              "                                    scoring=None, verbose=2))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_6u3JEKSb_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "a9f77c6a-5f50-4103-c52b-830d448090d0"
      },
      "source": [
        "pipeline.named_steps"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'onehotencoder': OneHotEncoder(cols=['quantity', 'waterpoint_type', 'extraction_type',\n",
              "                     'installer', 'funder', 'water_quality', 'basin', 'region',\n",
              "                     'payment', 'source', 'lga', 'ward', 'scheme_management',\n",
              "                     'management', 'subvillage', 'permit'],\n",
              "               drop_invariant=False, handle_missing='value',\n",
              "               handle_unknown='value', return_df=True, use_cat_names=False,\n",
              "               verbose=['quantity', 'waterpoint_type', 'extraction_type',\n",
              "                        'installer', 'funder', 'water_quality', 'basin',\n",
              "                        'region', 'payment', 'source', 'lga', 'ward',\n",
              "                        'scheme_management', 'management', 'subvillage',\n",
              "                        'permit', 'amount_tsh', 'gps_height', 'latitude',\n",
              "                        'longitude', 'region_code', 'district_code',\n",
              "                        'population', 'construction_year', 'pump_age',\n",
              "                        'year_recorded', 'month_recorded', 'day_recorded',\n",
              "                        'years']),\n",
              " 'randomizedsearchcv': RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
              "                    estimator=RandomForestRegressor(bootstrap=True,\n",
              "                                                    criterion='mse',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators='warn',\n",
              "                                                    n_jobs=None, oob_score=False,\n",
              "                                                    rando...\n",
              "                    param_distributions={'bootstrap': [True, False],\n",
              "                                         'max_depth': [10, 20, 30, 40, 50, 60,\n",
              "                                                       70, 80, 90, 100, 110,\n",
              "                                                       None],\n",
              "                                         'max_features': ['auto', 'sqrt'],\n",
              "                                         'min_samples_leaf': [1, 2, 4],\n",
              "                                         'min_samples_split': [2, 5, 10],\n",
              "                                         'n_estimators': [200, 400, 600, 800,\n",
              "                                                          1000, 1200, 1400, 1600,\n",
              "                                                          1800, 2000]},\n",
              "                    pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                    return_train_score=False, scoring=None, verbose=2),\n",
              " 'simpleimputer': SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
              "               missing_values=nan, strategy='mean', verbose=0),\n",
              " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCowPAYHaWnA",
        "colab_type": "code",
        "outputId": "bc3606a5-8b73-4329-9074-b2550f0b20ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 200)\n",
        "model = pipeline.named_steps['randomizedsearchcv']\n",
        "#encoder = pipeline.named_steps['onehotencoder']\n",
        "#encoded_columns = encoder.transform(X_train).columns \n",
        "best = pd.Series(model.best_params_)\n",
        "print(best)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_estimators         1400\n",
            "min_samples_split       5\n",
            "min_samples_leaf        1\n",
            "max_features         sqrt\n",
            "max_depth              30\n",
            "bootstrap            True\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZMpgC0GLX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_features['pump_age'] = 2013 - test_features['construction_year']\n",
        "test_features.loc[test_features['pump_age'] == 2013, 'pump_age'] = 0\n",
        "test_features.loc[test_features['pump_age'] == 0, 'pump_age'] = 10\n",
        "  \n",
        "test_features['region_district'] = test_features['region_code'].astype(str) + test_features['district_code'].astype(str)\n",
        "\n",
        "test_features['tsh_pop'] = test_features['amount_tsh']/test_features['population']\n",
        "\n",
        "test_features.drop(columns=['num_private'])\n",
        "\n",
        "X_test = test_features[features]\n",
        "\n",
        "assert all(X_test.columns == X_train.columns)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PQd-OKqGPT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#submission = sample_submission.copy()\n",
        "#submission['status_group'] = y_pred\n",
        "#submission.to_csv('/content/submission-01.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}